{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3e55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d243ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv('../ML_Clasification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a7eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar predictores y variable objetivo\n",
    "X = df.drop(columns=['ID', 'SeriousDlqin2yrs'])\n",
    "y = df['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5383562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División train/test\n",
    "data_test = pd.read_csv('../ML_Clasification/test.csv')\n",
    "X_test = data_test.drop(columns=['ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776612bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        129460\n",
       "1        134018\n",
       "2         86523\n",
       "3        138466\n",
       "4        143905\n",
       "          ...  \n",
       "44995    124596\n",
       "44996     75895\n",
       "44997     92453\n",
       "44998    139288\n",
       "44999     59825\n",
       "Name: ID, Length: 45000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01093f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Modelo: Arbol_Decision\n",
      "🔍 ROC AUC: 0.8006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     98016\n",
      "           1       0.61      0.09      0.16      6984\n",
      "\n",
      "    accuracy                           0.94    105000\n",
      "   macro avg       0.78      0.54      0.56    105000\n",
      "weighted avg       0.92      0.94      0.91    105000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m pipeline.fit(X, y)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Predicción de probabilidades\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m y_proba_train = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m     36\u001b[39m auc = roc_auc_score(y, y_proba_train)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🧪 Modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abelardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:904\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    903\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[32m    907\u001b[39m routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abelardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:371\u001b[39m, in \u001b[36mKNeighborsClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n\u001b[32m    369\u001b[39m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[32m    370\u001b[39m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     neigh_ind = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     neigh_dist = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abelardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:923\u001b[39m, in \u001b[36mKNeighborsMixin.kneighbors\u001b[39m\u001b[34m(self, X, n_neighbors, return_distance)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    920\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    921\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor set algorithm=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m._fit_method\n\u001b[32m    922\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m     chunked_results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minternal: _fit_method not recognized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abelardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abelardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abelardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abelardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Preprocesamiento: imputar y escalar\n",
    "numeric_features = X.columns.tolist()\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features)\n",
    "])\n",
    "\n",
    "# Modelos con hiperparámetros ajustados\n",
    "modelos = {\n",
    "    'Arbol_Decision': DecisionTreeClassifier(max_depth=3, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Random_Forest': RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluación\n",
    "mejor_modelo = None\n",
    "mejor_score = 0\n",
    "mejor_nombre = ''\n",
    "reportes = {}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', modelo)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    # Predicción de probabilidades\n",
    "    y_proba_train = pipeline.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, y_proba_train)\n",
    "    \n",
    "    print(f'\\n🧪 Modelo: {nombre}')\n",
    "    print(f'🔍 ROC AUC: {auc:.4f}')\n",
    "    print(classification_report(y, pipeline.predict(X)))\n",
    "\n",
    "    reportes[nombre] = auc\n",
    "    if auc > mejor_score:\n",
    "        mejor_score = auc\n",
    "        mejor_modelo = pipeline\n",
    "        mejor_nombre = nombre\n",
    "\n",
    "# Exportar predicciones\n",
    "y_pred_final = mejor_modelo.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024510a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m df_resultado = pd.DataFrame({\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mID\u001b[39m\u001b[33m'\u001b[39m: data_test.ID,\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPrediction\u001b[39m\u001b[33m'\u001b[39m: \u001b[43my_pred_final\u001b[49m\n\u001b[32m      4\u001b[39m })\n\u001b[32m      5\u001b[39m df_resultado.to_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpredicciones_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmejor_nombre.replace(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m).lower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Mejor modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmejor_nombre\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m con ROC AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmejor_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_pred_final' is not defined"
     ]
    }
   ],
   "source": [
    "df_resultado = pd.DataFrame({\n",
    "    'ID': data_test.ID,\n",
    "    'Prediction': y_pred_final\n",
    "})\n",
    "df_resultado.to_csv(f'predicciones_{mejor_nombre.replace(\" \", \"_\").lower()}.csv', index=False)\n",
    "\n",
    "print(f'\\n✅ Mejor modelo: {mejor_nombre} con ROC AUC: {mejor_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b562ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# 3. Preprocesador numérico ---------------------------------------------------\n",
    "num_feats = X.columns.tolist()\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, num_feats)\n",
    "])\n",
    "\n",
    "# 4. Utilidades ---------------------------------------------------------------\n",
    "auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def fit_model(pipe, params, name):\n",
    "    \"\"\"Ajusta RandomizedSearchCV y devuelve mejor modelo y mejor AUC.\"\"\"\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=params,\n",
    "        n_iter=20,\n",
    "        scoring=auc,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    y_pred_proba = search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "    y_pred_proba_T = search.best_estimator_.predict_proba(X)[:, 1]\n",
    "    test_auc = roc_auc_score(y, y_pred_proba_T)\n",
    "    print(f'{name:<20} | ROC AUC test = {test_auc:.4f}')\n",
    "    return name, search.best_estimator_, test_auc\n",
    "\n",
    "models_auc = {}\n",
    "\n",
    "# 5. XGBoost ------------------------------------------------------------------\n",
    "scale_pos = (y == 0).sum() / (y == 1).sum()\n",
    "xgb_pipe = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=scale_pos,\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "xgb_params = {\n",
    "    'clf__n_estimators': [200, 300, 400],\n",
    "    'clf__max_depth': [4, 6, 8],\n",
    "    'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'clf__subsample': [0.8, 1.0],\n",
    "    'clf__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "models_auc[*fit_model(xgb_pipe, xgb_params, 'XGBoost')[:2]] = fit_model(xgb_pipe, xgb_params, 'XGBoost')[2]\n",
    "\n",
    "# 6. LightGBM -----------------------------------------------------------------\n",
    "lgb_pipe = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        is_unbalance=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "lgb_params = {\n",
    "    'clf__n_estimators': [300, 500, 800],\n",
    "    'clf__learning_rate': [0.05, 0.1],\n",
    "    'clf__num_leaves': [31, 63, 127],\n",
    "    'clf__max_depth': [-1, 6, 8]\n",
    "}\n",
    "models_auc[*fit_model(lgb_pipe, lgb_params, 'LightGBM')[:2]] = fit_model(lgb_pipe, lgb_params, 'LightGBM')[2]\n",
    "\n",
    "# 7. AdaBoost + SMOTE ---------------------------------------------------------\n",
    "ada_pipe = ImbPipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('clf', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "ada_params = {\n",
    "    'clf__n_estimators': [100, 300],\n",
    "    'clf__learning_rate': [0.5, 1.0]\n",
    "}\n",
    "models_auc[*fit_model(ada_pipe, ada_params, 'AdaBoost')[:2]] = fit_model(ada_pipe, ada_params, 'AdaBoost')[2]\n",
    "\n",
    "# 8. RandomForest (balanced) ---------------------------------------------------\n",
    "rf_pipe = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "rf_params = {\n",
    "    'clf__n_estimators': [300, 500],\n",
    "    'clf__max_depth': [8, 12],\n",
    "    'clf__min_samples_split': [2, 10]\n",
    "}\n",
    "models_auc[*fit_model(rf_pipe, rf_params, 'RandomForest')[:2]] = fit_model(rf_pipe, rf_params, 'RandomForest')[2]\n",
    "\n",
    "# 9. GradientBoosting + SMOTE --------------------------------------------------\n",
    "gb_pipe = ImbPipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('clf', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "gb_params = {\n",
    "    'clf__n_estimators': [200, 400],\n",
    "    'clf__learning_rate': [0.05, 0.1],\n",
    "    'clf__max_depth': [3, 5]\n",
    "}\n",
    "models_auc[*fit_model(gb_pipe, gb_params, 'GradientBoosting')[:2]] = fit_model(gb_pipe, gb_params, 'GradientBoosting')[2]\n",
    "\n",
    "# 10. Seleccionar mejor modelo -------------------------------------------------\n",
    "best_name = max(models_auc, key=models_auc.get)\n",
    "best_model = models_auc[best_name]\n",
    "\n",
    "print(f'\\n🏆 Mejor modelo: {best_name} | ROC AUC test = {models_auc[best_name]:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Exportar predicciones ----------------------------------------------------\n",
    "best_pred = best_model.predict(X_test)\n",
    "out = pd.DataFrame({\n",
    "    'ID': data_test.ID,\n",
    "    'Prediction': y_pred_final\n",
    "})\n",
    "out.to_csv(f'XGCpredicciones_{best_name.replace(\" \", \"_\").lower()}.csv', index=False)\n",
    "print('Archivo CSV de predicciones guardado.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
